{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e295962",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»\n",
    "## Описание проекта\n",
    "Интернет-магазину «Викишоп» нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "Постройте модель со значением метрики качества F1 не меньше 0.75.\n",
    "\n",
    "## Инструкция для проекта\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели.\n",
    "3. Сделайте выводы.\n",
    "\n",
    "## Описание данных\n",
    "* Столбец text в нём содержит текст комментария, а toxic — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2443aa81",
   "metadata": {},
   "source": [
    "## 1. Загрузите и подготовьте данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70fa0458",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import warnings\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d7d226d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv('toxic_comments.csv')\n",
    "    display(df.info())\n",
    "    display(df.head())\n",
    "except:\n",
    "    df = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "    display(df.info())\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b608be",
   "metadata": {},
   "source": [
    "**Видим пропусков нет**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "727be127",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля токсичных комментов: 0.10167887648758234\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['toxic'].value_counts().plot(kind='bar')\n",
    "print('Доля токсичных комментов:',len(df[df['toxic']==1])/len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9c4fc8",
   "metadata": {},
   "source": [
    "**Данные несбалансированы - учтем в дальнейшем исследовании**\n",
    "\n",
    "**Подготовим данные к обучению**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41e7343f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "stop_words = set(nltk_stopwords.words('english'))\n",
    "punctuation = string.punctuation \n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f2e98a",
   "metadata": {},
   "source": [
    "**Прежде чем извлечь признаки из текста, упростим его.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f37ff4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def tokenize_lemmatize(text):\n",
    "    tokens = [word for sent in sent_tokenize(text) for word in word_tokenize(sent)]\n",
    "    tokens = list(filter(lambda t: t not in punctuation, tokens)) \n",
    "    tokens = list(filter(lambda t: t.lower() not in stop_words, tokens))\n",
    "    filtered_tokens = []\n",
    "    for i in tokens:\n",
    "        if re.search('[a-zA-Z]', i):\n",
    "            filtered_tokens.append(i)\n",
    "    filtered_tokens = list(\n",
    "        map(lambda token: wordnet_lemmatizer.lemmatize(token.lower()), filtered_tokens))\n",
    "    filtered_tokens = list(filter(lambda t: t not in punctuation, filtered_tokens))\n",
    "    return ' '.join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72630938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def tokenize_lemmatize(text):\n",
    "    tokens = [word for sent in sent_tokenize(text) for word in word_tokenize(sent)]\n",
    "    tokens = list(filter(lambda t: t not in punctuation, tokens)) \n",
    "    tokens = list(filter(lambda t: t.lower() not in stop_words, tokens))\n",
    "    tokens = list(\n",
    "        map(lambda token: wordnet_lemmatizer.lemmatize(token.lower(), get_wordnet_pos(token.lower())), tokens))\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48d5ab16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_clean'] = df['text'].map(tokenize_lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d3a30c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation edits make username hardcore metal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d'aww match background colour 'm seemingly stu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man 'm really try edit war 's guy constant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>`` ca n't make real suggestion improvement won...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>sir hero chance remember page 's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>`` second time ask view completely contradicts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>ashamed horrible thing put talk page 128.61.19.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>spitzer umm there actual article prostitution ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>look like actually put speedy first version de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>`` ... really n't think understand come idea b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "0       Explanation\\nWhy the edits made under my usern...      0   \n",
       "1       D'aww! He matches this background colour I'm s...      0   \n",
       "2       Hey man, I'm really not trying to edit war. It...      0   \n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4       You, sir, are my hero. Any chance you remember...      0   \n",
       "...                                                   ...    ...   \n",
       "159566  \":::::And for the second time of asking, when ...      0   \n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0   \n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0   \n",
       "159569  And it looks like it was actually you who put ...      0   \n",
       "159570  \"\\nAnd ... I really don't think you understand...      0   \n",
       "\n",
       "                                               text_clean  \n",
       "0       explanation edits make username hardcore metal...  \n",
       "1       d'aww match background colour 'm seemingly stu...  \n",
       "2       hey man 'm really try edit war 's guy constant...  \n",
       "3       `` ca n't make real suggestion improvement won...  \n",
       "4                        sir hero chance remember page 's  \n",
       "...                                                   ...  \n",
       "159566  `` second time ask view completely contradicts...  \n",
       "159567  ashamed horrible thing put talk page 128.61.19.93  \n",
       "159568  spitzer umm there actual article prostitution ...  \n",
       "159569  look like actually put speedy first version de...  \n",
       "159570  `` ... really n't think understand come idea b...  \n",
       "\n",
       "[159571 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52e51e9",
   "metadata": {},
   "source": [
    "**Разделим датасет на выборки**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d74094f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test, valid = train_test_split(df,test_size=0.2,shuffle = False)\n",
    "train, test = train_test_split(train_test, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70afd328",
   "metadata": {},
   "source": [
    "**Вычислим TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f78ef28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = train['text_clean'].values\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "tfidf_train = count_tf_idf.fit_transform(train_corpus)\n",
    "\n",
    "target_train = train['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adfa07d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_corpus = valid['text_clean'].values\n",
    "tfidf_valid = count_tf_idf.transform(valid_corpus)\n",
    "\n",
    "target_valid = valid['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5d484d",
   "metadata": {},
   "source": [
    "### Вывод: Таким образом, мы изучили данные и увидели, что классы несбалансированы. Также подготовили тексты к обучению: лемматизировали и поделили датасет на выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e6c196",
   "metadata": {},
   "source": [
    "## 2. Обучите разные модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c4df33",
   "metadata": {},
   "source": [
    "Обучим следующие модели:\n",
    "* LogisticRegression\n",
    "* RidgeClassifier\n",
    "* CatBoostClassifier\n",
    "* LGBMClassifier\n",
    "\n",
    "Посчитаем для них f1_score и выберем лучшую модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccb7453",
   "metadata": {},
   "source": [
    "**LogisticRegression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c6eea4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.7217160212604403\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression(random_state=12345)\n",
    "lr_model.fit(tfidf_train, target_train)\n",
    "\n",
    "predictions = lr_model.predict(tfidf_valid)\n",
    "print('f1_score:', f1_score(target_valid, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf38a001",
   "metadata": {},
   "source": [
    "**RidgeClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32484659",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.639320029563932\n"
     ]
    }
   ],
   "source": [
    "ridge_model = RidgeClassifier(alpha = 0.2, normalize = True, random_state=12345)\n",
    "ridge_model.fit(tfidf_train, target_train)\n",
    "predictions = ridge_model.predict(tfidf_valid)\n",
    "print('f1_score:', f1_score(target_valid, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f924ba94",
   "metadata": {},
   "source": [
    "**CatBoostClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e58b047",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.4354591\ttotal: 2.05s\tremaining: 1m 40s\n",
      "10:\tlearn: 0.2009289\ttotal: 21.3s\tremaining: 1m 15s\n",
      "20:\tlearn: 0.1789081\ttotal: 39.7s\tremaining: 54.8s\n",
      "30:\tlearn: 0.1666567\ttotal: 57.5s\tremaining: 35.2s\n",
      "40:\tlearn: 0.1582095\ttotal: 1m 15s\tremaining: 16.5s\n",
      "49:\tlearn: 0.1519247\ttotal: 1m 30s\tremaining: 0us\n",
      "F1_score: 0.6809588774118106\n"
     ]
    }
   ],
   "source": [
    "cat_model = CatBoostClassifier(learning_rate = 0.3, iterations=50, random_state=12345)\n",
    "cat_model.fit(tfidf_train, target_train, verbose=10)\n",
    "\n",
    "cat_predictions = cat_model.predict(tfidf_valid)\n",
    "cat_f1_score = f1_score(target_valid, cat_predictions)\n",
    "\n",
    "print(\"F1_score:\", cat_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd348aa",
   "metadata": {},
   "source": [
    "**LGBMClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db71eeaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.7516444444444444\n"
     ]
    }
   ],
   "source": [
    "lgbm_model = LGBMClassifier(learning_rate = 0.3, n_estimators = 20, num_iterations = 40, random_state=12345)\n",
    "lgbm_model.fit(tfidf_train, target_train)\n",
    "lgbm_predictions = lgbm_model.predict(tfidf_valid)\n",
    "lgbm_f1_score = f1_score(target_valid, lgbm_predictions)\n",
    "\n",
    "print(\"F1-score:\", lgbm_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673b8258",
   "metadata": {},
   "source": [
    "### Вывод: По итогу наилучшей моделью оказалась LGBMClassifier. Пороговое значение достигнуто. Проверим модель на тестовой выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35d9275",
   "metadata": {},
   "source": [
    "## 3. Сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68143ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7570175438596491"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test = test['toxic'] \n",
    "test_corpus = test['text_clean'].values.astype('U') \n",
    "\n",
    "tfidf_test = count_tf_idf.transform(test_corpus) \n",
    "\n",
    "lgbm_model = LGBMClassifier(learning_rate = 0.3, n_estimators = 20, num_iterations = 40, random_state=12345)\n",
    "\n",
    "lgbm_model.fit(tfidf_train, target_train)\n",
    "lgbm_predictions_test = lgbm_model.predict(tfidf_test) \n",
    "lgbm_f1_score = f1_score(target_test, lgbm_predictions_test) \n",
    "lgbm_f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08d3cf5",
   "metadata": {},
   "source": [
    "### Вывод: \n",
    "В данном проекте были решены следующие задачи:\n",
    "* Проведен анализ данных;\n",
    "* Подготовка данных к обучению;\n",
    "* Подбор наилучшей модели;\n",
    "* Финальная проверка лучшей модели на тестовой выборке.\n",
    "\n",
    "Таким образом, на тестовой выборке также удалось достичь значения в 0.75. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
