# `Проект`: Обучение модели классификации комментариев (обработка естественного языка, `NLP`)

## Описание проекта и Цель
Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. Нужна модель со значением метрики качества `F1` не меньше 0.75.
**Цель:** Обучить модель для классификации комментариев на хорошие и токсичные. 

## Описание датасета
В распоряжении имеется набор данных с разметкой о токсичности правок

## Применяемые библиотеки/модули
`pandas` `scikit-learn` `re` `catboost` `lightgbm` `nltk`
# Основные выводы

Изначально следует отметить, что данный проект разительно отличается от предыдущих, ввиду специфики работы с текстами.  

Прежде чем извлечь признаки из текста, нужно было провести работу по его упрощению,а именно: `лемматизация` и `токенизация`. Для этого была написана функция, однако все же не все слова приведелись к начальным формам. 
Чтобы корректно обработались все части речи, для `WordNetLemmatizer()` был использован `POS`-теги (Part of Speech, части речи). По итогу оставили только символы Латинского алфавита и привели к нижнему регистру.

Далее, для определения тональности рассчитали и применили величины `TF-IDF` как признаки + убрав частые неинформативные слова.

Теперь выделив признаки, можно приступать к обучению следующх моделей:
* LogisticRegression
* RidgeClassifier
* CatBoostClassifier
* LGBMClassifier  

По итогу наилучшей моделью оказалась LGBMClassifier. Итоговая проверка на тестовой выборке также показала себя хорошо, f1 = 0.76
