# `Проект`: Исследование технологического процесса очистки золота

## Описание проекта
Компания, разрабатывающая решения для эффективной работы промышленных предприятий, запрашивает прототип модели машинного обучения.  
Модель должна предсказать коэффициент восстановления золота из золотосодержащей руды. 
Модель поможет оптимизировать производство, чтобы не запускать предприятие с убыточными характеристиками.
По технологическому процессу очистки руды было решено, какие признаки нужны для построения модели, а какие — нет.  
`Крайне интересный и очень объемный проект, требовавший больших усилий и знаний. Сложность состояла в самой тематике, незнакомой лично для меня золотодобывающей технологии. Много работы также предстояло и для приведения датасета в порядок перед обучением`

Нужно было спрогнозировать сразу две величины:
* эффективность обогащения чернового концентрата;
* эффективность обогащения финального концентрата.
## Описание датасета
Данные с параметрами добычи и очистки.  
## Применяемые библиотеки
`pandas` `scikit-learn` `seaborn` `matplotlib.pyplot`
# Основные выводы
**Изучение** данных показало что тестовый датасет отличается от двух остальных по количеству признаков (53 против 87). Это объясняется тем, что замеряются некоторые данные значительно позже. Из-за этого в тестовой выборке отсутствуют некоторые признаки, которые есть в обучающей. Также в тестовом наборе нет целевых признаков.  

Также были замечены пропуски -  нужно было провести правильную предобработку данных для получения адекватных результатов анализа и моделей. 
Пропуски были заполнены предыдущим значением, поскольку, *по условию задачи* **соседние по времени параметры часто похожи**. В реализации идеи помог метод `ffill()`

Среди задач была **проверка расчета эффективности обогащения**. Для этого нужно было самим рассчитать данный показатель и посчитать `MAE (mean-squared error)`.  
Значение `MAE` получилось очень маленьким, что свидетельствует о том, что различия минимальны. Следовательно, вывод - эффективность обогащения рассчитана правильно.

Также в целях выснения, какие именно признаки не входят в тестовую выборку, был применен метод `difference()`, который возвращает количество столбцов train, которых нет в test.  
В test отсутствуют 34 признака:
* 30 из них с типом параметра output, они являются целевыми признаками, что есть причина тому, почему этих признаков нет в тестовой выборке;
* Остальные 4 с типом параметра calculation, данные признаки замеряются значительно позже, что также объясняет то, почему их нет в тестовой выборке.Это также значит, что данные признаки должны быть исключены перед обучением моделей.

Переходя к анализу данных, было крайне интересно посмотреть, как меняется концентрация металлов на различных этапах очистки. Для этого этапа были также построены графики.  
В общем и целом:
* Было явно, что золото растёт. Концентрация увеличилась с 7.65 до 44.87
* Серебро падает - это логично, мы же производим золото
* А свинец - побочный элемент химических реакций, поэтому не много увеличивается его содержание

Сравним распределения размеров гранул сырья на обучающей и тестовой выборках.  
Распределения визуально очень похожи => препятствий для получения правильной оценки модели нет
![image](https://user-images.githubusercontent.com/108406746/179096722-fca64d48-f05e-4c7a-8829-8dfce83c0477.png)

Далее, перед непосредственно обучением моделей необходимо было проделать следующие действия, требующих от data scientist-а определенный багаж знаний:
* Проверка и удаление аномалий;
* Написание функции, необходимой для расчета метрик `sMAPE`;
* Подготовка признаков и целевого признака;
* Приведение всех признаков к одному масштабу через `StandardScaler()`;
* Напиcание функции для оценки качества моделей `кросс-валидацией`. Отметим в функции параметр `greater_is_better` в `make_scorer()` равный `False`, т.к. в нашей задаче, чем ниже `sMAPE`, тем лучше.

Проделав все шаги выше, настало время переходить к обучению моделей и оценить их качество `кросс-валидацией`.  
Подбор гиперпараметров осуществлялся двум методами: `GridSearchCV` и обычные циклы `for`.
**Наилучшей моделью оказалась RandomForest. Проверяем ее на тестовой выборке.**
Далее модели были проверены на адекватность с помощью дамми модели: 
```
DummyRegressor(strategy="mean")
```
По итогу мы получили итоговый sMAPE = 9.59, адекватный показатель, учитывая sMAPE дамми-регрессора.
