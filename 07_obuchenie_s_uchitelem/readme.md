# `Проект`:Прогнозирование оттока клиента Банка (Обучение с учителем)

## Описание проекта и Цель
Из банка стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.\
На основе данных из банка нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет.



**Цель:** Построить модель с предельно большим значением `F1-меры`, довести метрику до 0.59. Измерить `AUC-ROC`, сравнив её значение с F1-мерой.

## Описание датасета
Предоставлены исторические данные о поведении клиентов и расторжении договоров с банком.
## Постановка задач
* Загрузить и подготовить данные.
* Исследовать баланс классов, обучить модель без учёта дисбаланса. Кратко описать выводы.
* Улучшить качество модели, учитывая дисбаланс классов. Обучить разные модели и найти лучшую. Кратко описать выводы.
* Провести финальное тестирование и сделать выводы

## Основные применяемые библиотеки
`pandas` `numpy` `scikit-learn` `matplotlib.pyplot` 

# Основные выводы
В данном проекте, перед тем, как приступить к обучению моделей, требовалось проделать достаточно много работы с приведением данных в порядок, а затем разобраться с самими признаками.

**Предобработка данных**
* После первичного изучения датасета была выявлена существенная доля пропусков в одном из столбцов, который описывает, сколько лет человек является клиентом банка. Изучение данного столбца показало, что значения колеблются от 0 до 10 лет.
Поскольку непонятна природа самих пропусков, было принято решение заполнить пропуски рандомными значениями от 0 до 10.
* Заметим также по признакам, что есть некоторые из них (rownumber, customerid, surname), которые точно не влияют на решение клиента отказаться от услуг банка. Поэтому данные признаки были удалены.

**Подготовка признаков к обучению**
* Обратим внимание на то, что у нас 2 категориальных признака: geography и gender. Признаки можно преобразовать, используя дамми-переменные, при этом исключив дамми-ловушку путем удаления по одному из столбцов у каждого преобразованного признака. Преобразовал категориальные признаки с помощью `прямого кодирования` (`OHE`).
* Далее можно уже было провести разделение данных на выборки, что и было сделано;
* У признаков также разный масштаб - они были стандартизированы через `StandardScaler`

Далее, по заданию, нужно было исследовать баланс классов и обучить модель без учёта дисбаланса, кратко описав выводы.
![image](https://user-images.githubusercontent.com/108406746/179015777-ab834fd7-dea3-4075-8f55-18a2124b257a.png)

Видно явно, что данные несбалансированные: 80% принимают значение 0 и 20% - 1.
Тем не менее, обучим, подобрав оптимальные гиперпараметры, 3 модели: `RandomForestClassifier`, `DecisionTreeClassifier`, `LogisticRegression` и посчитаем метрику `F1`.  
Обучив модель без учета дисбаланса получили, что лучшие F1 у RandomForestClassifier и DecisionTreeClassifier близки, в то время как у LogisticRegression F1 очень низкий. При этом требуемого значения метрики F1 = 0.59 достичь не удалось.  
**Следовательно качество моделей следовало улучшить**

Улучшение качества моделей происходило опробированием трех методов:
1. `Взвешивание классов`;
2. `Увеличение выборки`;
3. Перебор `порога классификации`, взяв за основу модель с `взвешенными классами`

По итогу лучшие модели с точки зрения F1 те, что были сбалансированы и с измененным порогом классифкации (3-й метод).
* Наилучшей моделью после тестирования оказалась RandomForestClassifier с F1 = 0.610
* Также близкой к 0.59 оказалась DecisionTreeClassifier с F1 = 0.587
* LogisticRegression в свою очередь получила самое низкое значение метрики F1 = 0.500

Приведем для сравнения значения AUC-ROC для каждой модели:
* RandomForestClassifier = 0.865
* DecisionTreeClassifier = 0.811
* LogisticRegression = 0.788

Видим, что значения AUC-ROC, которое является количественной интерпретацией ROC-кривой, расположены в той же иерархии, что и F1 моделей.
В целом, обозначим, что ROC предназначен для различных уровней порогов классификации и, следовательно, помогает посмотреть на общую картину. Если говорить об F1, то он вычисляется при заданном пороге и позволяет оценить качество модели точечно.
